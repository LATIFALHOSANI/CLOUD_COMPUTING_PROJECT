{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e260cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import json\n",
    "import os\n",
    "\n",
    "from models.model_xgboost import build_xgboost_model\n",
    "from models.model_lightgbm import build_lightgbm_model\n",
    "from models.model_random_forest import build_random_forest_model\n",
    "from models.model_logreg import build_logreg_model\n",
    "\n",
    "DATA_PATH = \"datasets/summit_dbe_processed.parquet\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b8b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50259, 138)\n",
      "is_failure\n",
      "0.0    49964\n",
      "1.0      295\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Load cleaned dataset\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df[\"is_failure\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cea131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (50259, 137)\n",
      "y shape: (50259,)\n"
     ]
    }
   ],
   "source": [
    "#Split X and y\n",
    "\n",
    "y = df[\"is_failure\"]\n",
    "X = df.drop(columns=[\"is_failure\"])\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee664668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (40207, 137)\n",
      "Test shape: (10052, 137)\n",
      "Failure rate train: 0.005869624692217773\n",
      "Failure rate test: 0.005869478710704337\n"
     ]
    }
   ],
   "source": [
    "#Train/test split with stratify\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X,\n",
    "y,\n",
    "test_size=0.2,\n",
    "random_state=42,\n",
    "stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Failure rate train:\", y_train.mean())\n",
    "print(\"Failure rate test:\", y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061fb44",
   "metadata": {},
   "source": [
    "We keep the same rare failure ratio in train and test so the model sees realistic data and the test set contains some DBE events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd62692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives: 39971\n",
      "positives: 236\n",
      "scale_pos_weight: 169.36864406779662\n"
     ]
    }
   ],
   "source": [
    "#Compute scale_pos_weight\n",
    "\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "print(\"negatives:\", neg)\n",
    "print(\"positives:\", pos)\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe7d89",
   "metadata": {},
   "source": [
    "The failure class is rare, so we upweight positive samples inside XGBoost instead of oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50168b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name, scale_pos_weight):\n",
    "    if model_name == \"xgboost\":\n",
    "        return build_xgboost_model(scale_pos_weight)\n",
    "    elif model_name == \"lightgbm\":\n",
    "        return build_lightgbm_model(scale_pos_weight)\n",
    "    elif model_name == \"random_forest\":\n",
    "        return build_random_forest_model()\n",
    "    elif model_name == \"logreg\":\n",
    "        return build_logreg_model()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "models_to_run = [\"xgboost\", \"lightgbm\", \"random_forest\", \"logreg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5f044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training model: xgboost\n",
      "============================================================\n",
      "Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "              n_jobs=-1, num_parallel_tree=None, ...)\n",
      "Training done.\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.998     0.997      9993\n",
      "         1.0      0.547     0.492     0.518        59\n",
      "\n",
      "    accuracy                          0.995     10052\n",
      "   macro avg      0.772     0.745     0.758     10052\n",
      "weighted avg      0.994     0.995     0.994     10052\n",
      "\n",
      "ROC-AUC: 0.8694628612910393\n",
      "Average precision: 0.5247600488192864\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.998     0.997      9993\n",
      "         1.0      0.547     0.492     0.518        59\n",
      "\n",
      "    accuracy                          0.995     10052\n",
      "   macro avg      0.772     0.745     0.758     10052\n",
      "weighted avg      0.994     0.995     0.994     10052\n",
      "\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.980     0.989      9993\n",
      "         1.0      0.162     0.661     0.260        59\n",
      "\n",
      "    accuracy                          0.978     10052\n",
      "   macro avg      0.580     0.820     0.624     10052\n",
      "weighted avg      0.993     0.978     0.985     10052\n",
      "\n",
      "\n",
      "Threshold: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.940     0.968      9993\n",
      "         1.0      0.067     0.729     0.123        59\n",
      "\n",
      "    accuracy                          0.939     10052\n",
      "   macro avg      0.533     0.834     0.546     10052\n",
      "weighted avg      0.993     0.939     0.963     10052\n",
      "\n",
      "\n",
      "Threshold: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.999     0.867     0.928      9993\n",
      "         1.0      0.034     0.797     0.066        59\n",
      "\n",
      "    accuracy                          0.867     10052\n",
      "   macro avg      0.516     0.832     0.497     10052\n",
      "weighted avg      0.993     0.867     0.923     10052\n",
      "\n",
      "\n",
      "Threshold: 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.999     0.668     0.800      9993\n",
      "         1.0      0.015     0.847     0.029        59\n",
      "\n",
      "    accuracy                          0.669     10052\n",
      "   macro avg      0.507     0.758     0.415     10052\n",
      "weighted avg      0.993     0.669     0.796     10052\n",
      "\n",
      "\n",
      "Threshold: 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.999     0.470     0.639      9993\n",
      "         1.0      0.010     0.898     0.020        59\n",
      "\n",
      "    accuracy                          0.472     10052\n",
      "   macro avg      0.504     0.684     0.329     10052\n",
      "weighted avg      0.993     0.472     0.635     10052\n",
      "\n",
      "Saved metrics to: results\\metrics_xgboost.json\n",
      "Saved feature importance to: results\\feature_importance_xgboost.csv\n",
      "\n",
      "============================================================\n",
      "Training model: lightgbm\n",
      "============================================================\n",
      "Model: LGBMClassifier(colsample_bytree=0.8, learning_rate=0.05, n_estimators=300,\n",
      "               n_jobs=-1, random_state=42,\n",
      "               scale_pos_weight=np.float64(169.36864406779662), subsample=0.8)\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 39971\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20533\n",
      "[LightGBM] [Info] Number of data points in the train set: 40207, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005870 -> initscore=-5.132078\n",
      "[LightGBM] [Info] Start training from score -5.132078\n",
      "Training done.\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.999     0.998      9993\n",
      "         1.0      0.737     0.475     0.577        59\n",
      "\n",
      "    accuracy                          0.996     10052\n",
      "   macro avg      0.867     0.737     0.788     10052\n",
      "weighted avg      0.995     0.996     0.995     10052\n",
      "\n",
      "ROC-AUC: 0.8915478122821568\n",
      "Average precision: 0.5464916777060144\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.999     0.998      9993\n",
      "         1.0      0.737     0.475     0.577        59\n",
      "\n",
      "    accuracy                          0.996     10052\n",
      "   macro avg      0.867     0.737     0.788     10052\n",
      "weighted avg      0.995     0.996     0.995     10052\n",
      "\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.998     0.998      9993\n",
      "         1.0      0.620     0.525     0.569        59\n",
      "\n",
      "    accuracy                          0.995     10052\n",
      "   macro avg      0.809     0.762     0.783     10052\n",
      "weighted avg      0.995     0.995     0.995     10052\n",
      "\n",
      "\n",
      "Threshold: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.995     0.996      9993\n",
      "         1.0      0.418     0.559     0.478        59\n",
      "\n",
      "    accuracy                          0.993     10052\n",
      "   macro avg      0.708     0.777     0.737     10052\n",
      "weighted avg      0.994     0.993     0.993     10052\n",
      "\n",
      "\n",
      "Threshold: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.992     0.995      9993\n",
      "         1.0      0.299     0.593     0.398        59\n",
      "\n",
      "    accuracy                          0.989     10052\n",
      "   macro avg      0.648     0.793     0.696     10052\n",
      "weighted avg      0.993     0.989     0.991     10052\n",
      "\n",
      "\n",
      "Threshold: 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.983     0.991      9993\n",
      "         1.0      0.191     0.678     0.299        59\n",
      "\n",
      "    accuracy                          0.981     10052\n",
      "   macro avg      0.595     0.831     0.645     10052\n",
      "weighted avg      0.993     0.981     0.986     10052\n",
      "\n",
      "\n",
      "Threshold: 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.972     0.985      9993\n",
      "         1.0      0.127     0.678     0.214        59\n",
      "\n",
      "    accuracy                          0.971     10052\n",
      "   macro avg      0.563     0.825     0.600     10052\n",
      "weighted avg      0.993     0.971     0.981     10052\n",
      "\n",
      "Saved metrics to: results\\metrics_lightgbm.json\n",
      "Saved feature importance to: results\\feature_importance_lightgbm.csv\n",
      "\n",
      "============================================================\n",
      "Training model: random_forest\n",
      "============================================================\n",
      "Model: RandomForestClassifier(class_weight='balanced', min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=300, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Training done.\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.996     1.000     0.998      9993\n",
      "         1.0      0.826     0.322     0.463        59\n",
      "\n",
      "    accuracy                          0.996     10052\n",
      "   macro avg      0.911     0.661     0.731     10052\n",
      "weighted avg      0.995     0.996     0.995     10052\n",
      "\n",
      "ROC-AUC: 0.8827331674545063\n",
      "Average precision: 0.4782135825027062\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.996     1.000     0.998      9993\n",
      "         1.0      0.826     0.322     0.463        59\n",
      "\n",
      "    accuracy                          0.996     10052\n",
      "   macro avg      0.911     0.661     0.731     10052\n",
      "weighted avg      0.995     0.996     0.995     10052\n",
      "\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.998     0.997      9993\n",
      "         1.0      0.578     0.441     0.500        59\n",
      "\n",
      "    accuracy                          0.995     10052\n",
      "   macro avg      0.787     0.719     0.749     10052\n",
      "weighted avg      0.994     0.995     0.994     10052\n",
      "\n",
      "\n",
      "Threshold: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.997     0.994     0.996      9993\n",
      "         1.0      0.368     0.542     0.438        59\n",
      "\n",
      "    accuracy                          0.992     10052\n",
      "   macro avg      0.683     0.768     0.717     10052\n",
      "weighted avg      0.994     0.992     0.993     10052\n",
      "\n",
      "\n",
      "Threshold: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.986     0.992      9993\n",
      "         1.0      0.217     0.678     0.329        59\n",
      "\n",
      "    accuracy                          0.984     10052\n",
      "   macro avg      0.608     0.832     0.661     10052\n",
      "weighted avg      0.993     0.984     0.988     10052\n",
      "\n",
      "\n",
      "Threshold: 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.931     0.964      9993\n",
      "         1.0      0.059     0.729     0.109        59\n",
      "\n",
      "    accuracy                          0.930     10052\n",
      "   macro avg      0.529     0.830     0.536     10052\n",
      "weighted avg      0.993     0.930     0.959     10052\n",
      "\n",
      "\n",
      "Threshold: 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     0.839     0.912      9993\n",
      "         1.0      0.028     0.780     0.054        59\n",
      "\n",
      "    accuracy                          0.839     10052\n",
      "   macro avg      0.513     0.809     0.483     10052\n",
      "weighted avg      0.993     0.839     0.907     10052\n",
      "\n",
      "Saved metrics to: results\\metrics_random_forest.json\n",
      "Saved feature importance to: results\\feature_importance_random_forest.csv\n",
      "\n",
      "============================================================\n",
      "Training model: logreg\n",
      "============================================================\n",
      "Model: LogisticRegression(C=0.1, class_weight='balanced', max_iter=500, n_jobs=-1)\n",
      "Training done.\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.994     0.998     0.996      9993\n",
      "         1.0      0.091     0.034     0.049        59\n",
      "\n",
      "    accuracy                          0.992     10052\n",
      "   macro avg      0.543     0.516     0.523     10052\n",
      "weighted avg      0.989     0.992     0.991     10052\n",
      "\n",
      "ROC-AUC: 0.628796089466016\n",
      "Average precision: 0.017209600966024717\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.994     0.998     0.996      9993\n",
      "         1.0      0.091     0.034     0.049        59\n",
      "\n",
      "    accuracy                          0.992     10052\n",
      "   macro avg      0.543     0.516     0.523     10052\n",
      "weighted avg      0.989     0.992     0.991     10052\n",
      "\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.040     0.078      9993\n",
      "         1.0      0.006     1.000     0.012        59\n",
      "\n",
      "    accuracy                          0.046     10052\n",
      "   macro avg      0.503     0.520     0.045     10052\n",
      "weighted avg      0.994     0.046     0.077     10052\n",
      "\n",
      "\n",
      "Threshold: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.013     0.025      9993\n",
      "         1.0      0.006     1.000     0.012        59\n",
      "\n",
      "    accuracy                          0.018     10052\n",
      "   macro avg      0.503     0.506     0.018     10052\n",
      "weighted avg      0.994     0.018     0.025     10052\n",
      "\n",
      "\n",
      "Threshold: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.004     0.007      9993\n",
      "         1.0      0.006     1.000     0.012        59\n",
      "\n",
      "    accuracy                          0.009     10052\n",
      "   macro avg      0.503     0.502     0.009     10052\n",
      "weighted avg      0.994     0.009     0.007     10052\n",
      "\n",
      "\n",
      "Threshold: 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      9993\n",
      "         1.0      0.006     1.000     0.012        59\n",
      "\n",
      "    accuracy                          0.006     10052\n",
      "   macro avg      0.003     0.500     0.006     10052\n",
      "weighted avg      0.000     0.006     0.000     10052\n",
      "\n",
      "\n",
      "Threshold: 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000      9993\n",
      "         1.0      0.006     1.000     0.012        59\n",
      "\n",
      "    accuracy                          0.006     10052\n",
      "   macro avg      0.003     0.500     0.006     10052\n",
      "weighted avg      0.000     0.006     0.000     10052\n",
      "\n",
      "Saved metrics to: results\\metrics_logreg.json\n",
      "Model has no feature_importances_ attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\latifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_to_run:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # BUILD THE MODEL FOR THIS ITERATION\n",
    "    # -----------------------------------------\n",
    "    model = build_model(model_name, scale_pos_weight)\n",
    "    print(\"Model:\", model)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # TRAIN\n",
    "    # -----------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Training done.\")\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # EVALUATE AT DEFAULT THRESHOLD (0.5)\n",
    "    # -----------------------------------------\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, digits=3)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "    avg_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "    print(\"Classification report (threshold=0.5):\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"ROC-AUC:\", roc_auc)\n",
    "    print(\"Average precision:\", avg_precision)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # THRESHOLD SWEEP\n",
    "    # -----------------------------------------\n",
    "    thresholds = [0.5, 0.2, 0.1, 0.05, 0.02, 0.01]\n",
    "    threshold_results = []\n",
    "\n",
    "    for t in thresholds:\n",
    "        preds = (y_prob > t).astype(int)\n",
    "        r = classification_report(y_test, preds, output_dict=True, digits=3)\n",
    "\n",
    "        if \"1\" in r:\n",
    "            rec_1 = r[\"1\"][\"recall\"]\n",
    "            prec_1 = r[\"1\"][\"precision\"]\n",
    "        else:\n",
    "            rec_1 = 0.0\n",
    "            prec_1 = 0.0\n",
    "\n",
    "        threshold_results.append({\n",
    "            \"threshold\": t,\n",
    "            \"recall_failure\": rec_1,\n",
    "            \"precision_failure\": prec_1,\n",
    "        })\n",
    "\n",
    "        print(\"\\nThreshold:\", t)\n",
    "        print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # SAVE METRICS\n",
    "    # -----------------------------------------\n",
    "    metrics = {\n",
    "        \"model\": model_name,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": avg_precision,\n",
    "        \"report_threshold_0_5\": report,\n",
    "        \"threshold_results\": threshold_results,\n",
    "    }\n",
    "\n",
    "    metrics_path = os.path.join(RESULTS_DIR, f\"metrics_{model_name}.json\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    print(\"Saved metrics to:\", metrics_path)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # SAVE FEATURE IMPORTANCE (TREE MODELS ONLY)\n",
    "    # -----------------------------------------\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        fi_df = pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"importance\": importances,\n",
    "        }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "        fi_path = os.path.join(RESULTS_DIR, f\"feature_importance_{model_name}.csv\")\n",
    "        fi_df.to_csv(fi_path, index=False)\n",
    "        print(\"Saved feature importance to:\", fi_path)\n",
    "    else:\n",
    "        print(\"Model has no feature_importances_ attribute.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
